# ğŸ“Š Projet de Scraping et PrÃ©paration de DonnÃ©es pour LLM

## âœ¨ Objectif

Ce projet a pour objectif de scraper, structurer et enrichir des donnÃ©es de formations issues d'un site web, en vue d'une exploitation par un LLM (Large Language Model) pour un systÃ¨me de recommandation de parcours personnalisÃ©.

Il permet d'automatiser :

- L'extraction HTML via Playwright
- Le nettoyage + enrichissement des donnÃ©es (BeautifulSoup)
- La prÃ©paration Ã  la vectorisation (chunking)
- La gÃ©nÃ©ration de documentation automatique

## ğŸ§° Stack Technique

- **Python 3.12**
- **Playwright** : scraping dynamique (Angular)
- **BeautifulSoup** : nettoyage HTML
- **pandas** : manipulation tabulaire
- **ChromaDB** : stockage des embeddings (optionnel)
- **SentenceTransformers** / **OpenAI** : vectorisation (au choix)

## ğŸ“š Structure du pipeline

```
project/
â”œâ”€â”€ main.py                      # Scraping initial des pages de formation
â”œâ”€â”€ clean.py                     # Nettoyage, enrichissement, extraction du rÃ©sumÃ© HTML
â”œâ”€â”€ prepare_vectorisation.py     # Chunking + structuration prÃªte pour LLM
â”œâ”€â”€ vectorize_chunks.py          # Vectorisation des textes (SentenceTransformers ou OpenAI)
â”œâ”€â”€ README_generator.py          # CrÃ©ation automatique d'un rÃ©capitulatif des formations
â”œâ”€â”€ run_pipeline.py              # ExÃ©cution interactive du pipeline complet
â”œâ”€â”€ content/
â”‚   â”œâ”€â”€ json/formations/        # Fichiers JSON individuels par formation
â”‚   â””â”€â”€ csv/formations/         # Fichiers CSV individuels par formation
â””â”€â”€ README.md                   # Ce fichier
```

## ğŸ”§ Utilisation

### 1. Scraping des formations

```bash
python main.py
```

> CrÃ©e les fichiers JSON et CSV Ã  partir du site source

### 2. Nettoyage et enrichissement

```bash
python clean.py
```

> Nettoie le HTML, ajoute les mÃ©tadonnÃ©es, un rÃ©sumÃ© HTML, et une colonne `niveau`

### 3. PrÃ©paration Ã  la vectorisation

```bash
python prepare_vectorisation.py
```

> Divise le texte des formations en *chunks* prÃªts Ã  Ãªtre vectorisÃ©s (tokenisation, metadata, etc.)

### 4. Vectorisation

```bash
python vectorize_chunks.py
```

> Convertit les chunks en vecteurs, et les stocke dans **ChromaDB** (optionnel si vectorisation confiÃ©e au collaborateur)

### 5. GÃ©nÃ©ration du README

```bash
python README_generator.py
```

> GÃ©nÃ¨re automatiquement un tableau rÃ©capitulatif de toutes les formations

### 6. ExÃ©cution guidÃ©e du pipeline

```bash
python run_pipeline.py
```

> Permet de sÃ©lectionner les Ã©tapes Ã  lancer via un menu interactif (scraping, cleaning, etc.)

## ğŸ“Š Exemple de rÃ©sultat

Le fichier `content/README.md` liste toutes les formations disponibles sous forme de tableau :

| Titre               | Niveau        | DurÃ©e   | ModalitÃ© | Lieu       | Tarif   |
| ------------------- | ------------- | ------- | -------- | ---------- | ------- |
| Formation SQL/NoSQL | IntermÃ©diaire | 3 jours | Hybride  | Ã€ distance | 2100 HT |
| ...                 | ...           | ...     | ...      | ...        | ...     |

## ğŸŒ Auteur du pipeline

**Michel**, Data Analyst passionnÃ© de structuration, UX, et pipeline intelligents.

## âœ¨ Prochaine Ã©tape

L'intÃ©gration du **LLM** sera prise en charge par **Mohammed**, en partant des donnÃ©es enrichies par ce pipeline.

> âœ‰ï¸ Ce projet est en constante Ã©volution. Chaque Ã©tape est modulable et documentÃ©e.

---

*"Vers l'infini et au-delÃ  !"*

